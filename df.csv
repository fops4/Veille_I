Titre,Date,Contenu,Lien Video,Etat,Résumé
OpenAI renoue avec l'ouverture avec deux modèles open-weight : GPT-OSS-120B et GPT-OSS-20B,06/08/2025,"OpenAI a annoncé hier soir la sortie de deux modèles de langage open-weight, gpt-oss-120B et gpt-oss-20B, disponibles sous licence Apache 2.0. Cette démarche marque un tournant pour l’entreprise, qui n’avait plus proposé de LLM open-weight depuis GPT-2. Les poids des modèles sont accessibles publiquement sur Hugging Face.
Des modèles conçus pour le raisonnement et l’efficacité
Les deux modèles reposent sur une architecture Mixture-of-Experts (MoE), avec respectivement 117 milliards et 21 milliards de paramètres au total, mais n’activant qu’une fraction (5,1B pour le 120B, 3,6B pour le 20B) à chaque token. Tous deux supportent une longueur de contexte étendue à 128 000 tokens.
OpenAI revendique des performances compétitives sur les tâches de raisonnement. GPT-OSS-120B atteindrait des résultats proches de o4-mini sur les benchmarks classiques (MMLU, HLE, TauBench…), tout en étant exécutable sur un seul GPU de 80 Go. Le modèle 20B, plus léger, est annoncé comme fonctionnant avec 16 Go de mémoire, ce qui le rend potentiellement utilisable en local ou sur des appareils embarqués.
GPT-OSS est testable ici
Compatibilité et cas d’usage
Ces modèles sont compatibles avec l’API Responses d’OpenAI, et intègrent nativement la prise en charge du Chain-of-Thought (CoT), des appels de fonctions, des sorties structurées et de l’ajustement de l’effort de raisonnement selon la tâche.
OpenAI cible des usages dans les workflows agentiques, le développement d’assistants intelligents, la recherche, ou encore le déploiement en local pour des raisons de sécurité ou de souveraineté des données. Des partenaires comme AI Sweden, Orange et Snowflake ont été impliqués en amont du lancement pour explorer des cas concrets d’intégration.
Sécurité et évaluation des risques
OpenAI a longtemps expliqué son pivot vers des modèles fermés par des enjeux sécuritaires. La sécurité a donc été au coeur des considérations de la société, et a été à l'origine de plusieurs reports de cette livraison de modèles Open Weight tant attendus. OpenAI affirme aujourd'hui avoir intégré des mécanismes avancés de filtrage et de post-formation pour réduire les risques liés à la mise à disposition publique. Une évaluation par des experts externes a notamment été menée sur des versions délibérément fine-tunées de manière malveillante (cybersécurité, biologie), dans le cadre du Preparedness Framework d’OpenAI.
Selon l’entreprise, même dans ces scénarios extrêmes, les modèles n’atteindraient pas des niveaux de capacités préoccupants. Un challenge de red teaming doté de 500 000 $ a par ailleurs été lancé sur Kaggle pour encourager la détection collaborative de vulnérabilités.
Un retour maîtrisé à l’open source ?
Ce lancement soulève plusieurs questions. D’une part, il témoigne d’une volonté de rééquilibrer l’offre entre modèles propriétaires puissants et alternatives open source. D’autre part, il permet à OpenAI de garder une longueur d’avance technique tout en cadrant les usages, en fixant de nouveaux standards de sécurité pour l’open-weight.
La publication des poids sous licence permissive, l’outillage mis à disposition (inférences optimisées, harmony renderer, support PyTorch et Metal…), ainsi que les partenariats avec Azure, Hugging Face ou Vercel visent à faciliter l’adoption dans un écosystème de plus en plus fragmenté.
Reste à voir dans quelle mesure ces modèles seront repris par la communauté, notamment face aux alternatives comme Mistral, LLaMA, Mixtral ou Yi, et si leur ouverture effective (notamment la possibilité de fine-tuning libre) suffira à répondre aux attentes des chercheurs et développeurs.
 
Découvrez les fiches modèles sur Hugging Face :
https://huggingface.co/openai/gpt-oss-20b
https://huggingface.co/openai/gpt-oss-120b
 
 


                        Cet article publirédactionnel est publié dans le cadre d'une collaboration commerciale",,envoyé,"Voici un résumé du texte en 4 phrases maximum, en insistant sur les points clés :

OpenAI a publié deux modèles de langage open-weight, GPT-OSS-120B et GPT-OSS-20B, disponibles sous licence Apache 2.0. Les modèles, conçus pour le raisonnement et l'efficacité, ont une architecture Mixture-of-Experts avec 117 milliards et 21 milliards de paramètres respectivement. Ils sont compatibles avec l'API d'OpenAI et intègrent des fonctionnalités telles que la prise en charge du Chain-of-Thought et de l'ajustement de l'effort de raisonnement. Les poids des modèles sont accessibles publiquement sur Hugging Face."
Festival AI4GOOD : démocratiser l’IA au service des jeunes et du développement durable,06/08/2025,"Lancé en 2024 à l’île Maurice par Charlotte Govin, le Festival AI4GOOD ne se contente pas de célébrer la créativité assistée par l’IA générative. Il ambitionne d’en faire un levier d’inclusion et d’autonomisation, en dotant les jeunes, notamment ceux issus de régions sous-représentées comme l’Afrique ou le Pacifique, des moyens de s’approprier ces technologies pour concevoir des solutions concrètes, adaptées à leurs réalités locales.




Dès sa première édition, l’initiative a mis l’accent sur le continent africain. Avec 60 % de sa population âgée de moins de 25 ans, l’Afrique recèle un immense vivier de talents. Mais dans de nombreux pays, les infrastructures numériques, les ressources éducatives et la connectivité Internet restent inégalement réparties, en particulier dans les zones rurales, limitant l’accès aux compétences numériques.
Face à ce constat, Charlotte Govin a créé une organisation à but non lucratif pour transmettre aux jeunes Africains des compétences pratiques, qui leur permettront de contribuer à une croissance numérique responsable. Sa démarche s’inscrit pleinement dans les Objectifs de Développement Durable (ODD), en particulier ceux liés à l’éducation de qualité, l’égalité des genres, la lutte contre les inégalités numériques et le changement climatique.
Lors de la première édition en 2024, 80 jeunes de l’île Maurice et de Madagascar ont présenté un court-métrage réalisé avec des outils d’IA générative. En 2025, le programme s’est étendu à d’autres territoires : Sénégal, Afrique du Sud, Comores, Nouvelle-Calédonie...
La compétition s’adresse aux 12–25 ans, invités à concourir localement cette année dans deux catégories : court-métrage et jeu vidéo. Deux thématiques leur ont été proposées : “Good Tech, Bad Tech”, une réflexion sur les dilemmes éthiques liés à la technologie, et “Superhero Everyday”, une mise en lumière des héros du quotidien.
Les participants disposaient de trois semaines pour produire leur œuvre. L’organisation leur a fourni gratuitement les licences des outils d’IA nécessaires, ainsi que des sessions de formation (en direct ou en replay). L'accompagnement d'un mentor était également proposé, s'ils le désiraient. 
Chaque projet lauréat au niveau local a été ensuite évalué par un jury international. Dans la catégorie des 20–25 ans, c’est Vinciane Henintsoa qui a remporté la palme internationale grâce à un court-métrage ""impeccablement réalisé"" selon le jury, à la fois clair dans son message et subtil dans son traitement. Voir la vidéo.
Fort de cette seconde édition réussie, le Festival AI4GOOD ambitionne de devenir la plus grande initiative mondiale dédiée à la jeunesse et étendre sa présence dans plus de 50 villes dans les années à venir. Ce déploiement sera appuyé par la création d’une plateforme éducative ouverte, offrant à tous des ressources gratuites pour se former à l'IA.
Il entend également peser dans les débats sur les politiques et l’éthique de l’IA.
Pour retrouver d'autres courts-métrages présentés lors des festivals : AI4GOOD Festival - YouTube",https://www.youtube.com/embed/jm-uyAeSWzY,envoyé,"Voici un résumé du texte en 4 phrases :

Le Festival AI4GOOD, lancé en 2024 à l'île Maurice, vise à promouvoir l'inclusion et l'autonomisation des jeunes, en particulier issus de régions sous-représentées, en leur apprenant à utiliser l'intelligence artificielle générative pour concevoir des solutions concrètes. La première édition a mis l'accent sur l'Afrique, où l'initiative a permis à 80 jeunes de réaliser des court-métrages avec des outils d'IA. Les participants ont été invités à concourir dans deux catégories et ont bénéficié d'un accompagnement et d'une formation gratuite. Le festival ambitionne de devenir la plus grande initiative mondiale dédiée à la jeunesse et d'étendre sa présence dans plus de 50 villes dans les années à venir."
Orange et OpenAI : une alliance stratégique pour une IA souveraine et responsable,06/08/2025,Contenu non trouvé,,envoyé,"Je suis désolé, mais il semble que le texte que vous avez fourni n'est pas accessible. Veuillez le partager avec moi, et je serai ravi de vous aider à résumer les points clés en 3 ou 4 phrases maximum."
L’IA pour tous : le Groupe IGENSIA Education met la GenAI au cœur de ses parcours pédagogiques,04/08/2025,"Groupe indépendant et associatif à but non lucratif, fort de cinquante années d’expertise dans l’enseignement supérieur et la formation professionnelle, IGENSIA Education continue d'innover en intégrant, dès septembre prochain, un socle commun de formation à l’IA générative dans l’ensemble de ses cursus. Cette initiative vise à promouvoir une approche raisonnée et éthique des outils GenAI.
Fondé en 1975 sous le nom d’Institut de Gestion Sociale (IGS), le Groupe IGENSIA Education s’est construit autour d’une mission fondatrice : proposer un modèle éducatif ouvert à tous, centré sur l’épanouissement et l’engagement des apprenants. Il articule son action autour de cinq pôles : écoles, alternance, formation continue, insertion-inclusion et orientation.
Présent sur quatre campus en France (Paris, Lyon, Toulouse et Nanterre) et un cinquième à Casablanca, le Groupe accueille chaque année près de 15 000 apprenants, dont 9 300 alternants. Il s’appuie sur un réseau actif de plus de 10 000 entreprises partenaires, 80 000 alumni et des équipes pédagogiques issues à la fois du monde académique et de l’entreprise.
Son offre de formation, qui s’étend de Bac à Bac+6, et jusqu’au Bac+8 avec le Doctorate in Business Administration (DBA), couvre un large éventail de filières : ressources humaines, commerce, finance, droit, immobilier, communication, informatique ou journalisme. Ces parcours sont déployés au sein d’écoles reconnues telles que IGS-RH, ISCPA, ICD, ESAM, IPI, IMSI ou encore l’American Business School of Paris. Le Groupe soutient également l’entrepreneuriat étudiant via son incubateur Why Not Factory, et développe des partenariats académiques internationaux en Europe, Afrique et Asie.
Former les acteurs du monde de demain
Avec ce socle commun de formation à l’IA, le Groupe ambitionne de développer l'esprit critique des apprenants, et encourager un usage éthique, responsable et frugal des outils GenAI.  
Intégrée au programme transversal Questions du temps présent, cette formation de 15 heures s’articule autour de cinq modules :


L’abécédaire de l’IA : compréhension des fondamentaux de l'IA (histoire, applications et enjeux contemporains) ; 


Littératie IA : pour aller au-delà du simple usage et comprendre les limites et risques des outils GenAI ;


Éthique et frugalité : introduire une réflexion critique sur les biais, les usages responsables et les impacts environnementaux ;


Prompt engineering : former à la formulation efficace de requêtes, compétence déjà prisée dans de nombreux métiers ;


Utilisation dans le parcours de formation : création d’assistants IA personnalisés sans codage pour soutenir l’apprentissage, de façon transparente et conforme à la charte IA du Groupe.


Ce socle commun s’appuie sur le référentiel de compétences apprenantes de l’UNESCO, assurant une cohérence pédagogique et une reconnaissance internationale.
Une déclinaison métier contextualisée
Chaque école du Groupe adaptera la formation à son domaine. Ainsi, l’IMSI mobilisera l’IA autour des cas d’usage liés à l’immobilier, comme la recherche automatisée de biens ou la prédiction de tendances de marché. À l’ISCPA et à l’EMI, les thématiques porteront davantage sur la rédaction assistée, la vérification de contenus ou encore la détection de deepfakes.
Cette démarche s’inscrit dans une stratégie d’intégration progressive de l’IA, amorcée en 2024 avec le changement de nom du Groupe :  170 enseignants et 70 collaborateurs, ont déjà été formés aux outils et aux enjeux éthiques, des chartes internes à destination des équipes pédagogiques et des étudiants ont été élaborées. Le Groupe s’est également appuyé sur des partenaires technologiques tels que la start-up BRIO, spécialisée dans les simulations d’entretien, ou Stellia, qui développe des assistants d’apprentissage personnalisés.
Loren Resal, Directrice du développement digital et pédagogique du Groupe, résume cette ambition :
""Pour le Groupe IGENSIA Education, il est important d’imaginer un futur où l’IA et la pédagogie se conjuguent pour révéler les talents. La démarche que nous menons en interne réaffirme notre rôle de former les acteurs de la métamorphose, en plaçant l’intelligence artificielle au service de la pédagogie, dans une logique d’innovation durable, responsable et surtout éthique"".",,envoyé,"Voici un résumé du texte en 4 phrases maximum :

IGENSIA Education, un groupe indépendant et associatif à but non lucratif, célèbre cinquante ans d'expertise dans l'enseignement supérieur et la formation professionnelle. Dans une démarche d'innovation, le groupe intègre un socle commun de formation à l'intelligence artificielle générative (IA) dans ses cursus, pour promouvoir une approche éthique et responsable de l'utilisation des outils GenAI. Cette formation, validée par le référentiel de compétences apprenantes de l'UNESCO, vise à développer l'esprit critique des apprenants et à encourager un usage éthique des outils GenAI. Chaque école du groupe adaptera la formation à son domaine, en intégrant l'IA dans les cas d'usage relevant de leur métier."
Nouvelle étape pour l'AI Act : les obligations pour les modèles d'IA à usage général sont entrées en vigueur,04/08/2025,"Les premières dispositions de l'AI Act, entré en vigueur en août 2024, concernant les systèmes d'IA à risque inacceptables ont commencé à être appliquées en février dernier. Malgré le moratoire ""Stop the Clock"" demandé par une cinquantaine d'entreprises de l’EU AI Champions Initiative sur la poursuite du déploiement du règlement, les obligations concernant les modèles d'IA à usage général (GPAI) sont effectives depuis samedi dernier.
L’UE a été pionnière dans l'établissement d'un cadre réglementaire visant à réguler l’IA en fonction de son potentiel à causer des dommages. L'objectif de l'AI Act ou RIA est de garantir que les systèmes et modèles d’IA commercialisés au sein de l’UE soient utilisés de manière éthique, sûre et dans le respect des droits fondamentaux de l’UE.
Les lignes directrices publiées par la Commission européenne le 18 juillet dernier clarifient l’application du champ d'application de la réglementation pour les modèles GPAI. Tout modèle d'IA affichant une capacité de calcul supérieure à 10²³ FLOPs (soit le volume d’opérations en virgule flottante mobilisées lors de l’entraînement), conçu sans finalité précise (prévisions météorologiques, jeux...) mais pouvant être réutilisé dans une large variété de contextes, sera présumé entrer dans cette catégorie. 
Les obligations couvrent l’ensemble du cycle de vie des modèles, du pré-entraînement à la mise à disposition, en passant par les mises à jour et les modifications postérieures à la mise sur le marché. Leurs fournisseurs devront fournir:


une documentation technique exhaustive, à destination des fournisseurs en aval intégrant le modèle dans leur système IA et, si demandée, au Bureau européen de l'IA (AI Office) ou aux autorités nationales compétentes. ;


un résumé des données d'entraînement, selon le modèle standardisé que l'AI Office leur fournira ;


mettre en place une politique sur le respect des droits d’auteur, alignée avec le droit européen.


Le principe fondamental du règlement demeure inchangé :  plus le risque est élevé, plus les exigences sont fortes. Ces obligations sont renforcées pour les GPAI considérés à risque systémique, des modèles dépassant le seuil de 10²⁵ FLOPs cumulés. Ceux-ci devront faire l’objet de procédures de gestion des risques renforcées, notamment en matière de cybersécurité, de signalement des incidents graves, ou encore de tests continus. Une charge réglementaire estimée difficilement soutenable...
Ce seuil n'est cependant pas rigide : une réévaluation des risques réels peut être demandée par les prestataires.
Fournisseurs, modifications et statut open source
Toute entreprise qui met un modèle sur le marché européen est considérée comme fournisseur, indépendamment du lieu de développement initial. Cependant, un acteur en aval qui a effectué une modification du modèle en utilisant plus d’un tiers de sa puissance de calcul initiale, est lui aussi considéré comme fournisseur et soumis aux obligations.
Les modèles publiés sous licence libre et ouverte bénéficient d’un régime d’exemption partielle. À condition de respecter certains critères (absence de monétisation ou de collecte de données personnelles), ces modèles ne sont pas soumis aux obligations de documentation aux fournisseurs en aval ou aux autorités. Cependant, dès qu’ils franchissent le seuil de risque systémique, aucune exemption ne s’applique. 
Code de bonnes pratiques
Malgré leur entrée en vigueur le 2 août dernier, ces règles ne s'appliqueront qu’en août 2026 pour les nouveaux modèles, et en août 2027 pour les modèles existants. Cette progressivité, pilotée par le Bureau de l’IA, vise à laisser aux entreprises le temps de s’adapter.
Pour aider les fournisseurs à s'y conformer, la Commission a publié, quelques jours avant ses directives, un code de bonnes pratiques. Ceux qui choisissent d'y adhérer bénéficieront d’une réduction de leur charge administrative et d’une sécurité juridique accrue par rapport à ceux qui prouveront leur conformité par d'autres moyens. Google, OpenAI, Mistral, Microsoft l'ont déjà fait tandis que Meta a refusé, invoquant des zones d’incertitudes juridiques et une extension injustifiée du cadre réglementaire.
Les amendes prévues pour non-respect de ces obligations pourront atteindre 15 millions d'euros ou 3% du chiffre d'affaires mondial des entreprises. Chacun des États membres de l'UE doit notifier à la Commission les autorités de surveillance qui contrôleront les entreprises. Si aucune n'a été pour l'instant désignée par la France, la Cnil devrait jouer un rôle central, des instances sectorielles comme l'Arcom ou l'Anssi sont également envisagées.",,envoyé,"Voici un résumé du texte en 4 phrases :

L'Union Européenne a mis en place un règlement pour réglementer les systèmes d'intelligence artificielle (IA) à usage général (GPAI), entrant en vigueur en août 2024. Les fournisseurs de ces modèles d'IA doivent fournir une documentation technique exhaustive, un résumé des données d'entraînement et mettre en place une politique de respect des droits d'auteur. Les modèles considérés à risque systique doivent faire l'objet de procédures de gestion des risques renforcées. Les non-respect de ces obligations peut entraîner des amendes jusqu'à 15 millions d'euros ou 3% du chiffre d'affaires mondial des entreprises."
Sécurité des puces H20 : Pékin convoque NVIDIA après des soupçons de fonctions de traçage à distance,01/08/2025,"Le 31 juillet 2025, l’Administration chinoise du cyberespace (CAC) a convoqué NVIDIA pour s’expliquer sur d’éventuelles vulnérabilités de sécurité identifiées dans ses puces H20, spécifiquement destinées au marché chinois. Cette convocation intervient sur fond de tensions persistantes entre les États-Unis et la Chine autour des technologies de calcul avancé et de l’intelligence artificielle.
Des accusations liées à des capacités de ""traçage"" et de ""désactivation à distance""
Selon plusieurs médias chinois et experts en cybersécurité cités par la presse locale, les puces H20 de NVIDIA intégreraient des fonctions de tracking et de remote shutdown (fermeture à distance), permettant potentiellement une désactivation unilatérale ou une localisation des appareils. Ces capacités technologiques avaient déjà été évoquées plus tôt par certains élus américains, qui soutiennent l’intégration de mécanismes de contrôle dans les semi-conducteurs exportés vers des pays tiers, notamment la Chine.
D’après des déclarations relayées par les médias officiels, ces technologies de suivi seraient désormais « matures » et opérationnelles dans les dernières générations de puces IA de NVIDIA, notamment les H20, conçues comme version bridée des puces A100/H100 pour se conformer aux restrictions américaines à l’export.
Une réponse réglementaire fondée sur la législation chinoise
S’appuyant sur la Loi sur la cybersécurité, la Loi sur la sécurité des données et la Loi sur la protection des informations personnelles, le régulateur chinois a exigé de NVIDIA une réponse formelle sur les risques potentiels associés à ces composants. L’entreprise américaine devra fournir des preuves techniques et documentaires relatives aux failles alléguées, ainsi qu'une démonstration de conformité avec la législation locale en matière de souveraineté numérique et de sécurité des infrastructures critiques.
L’entretien du 31 juillet s’inscrit dans un contexte plus large de réaffirmation du contrôle technologique par la Chine, qui a récemment durci ses exigences sur les équipements informatiques étrangers utilisés dans les entreprises publiques, les infrastructures critiques et les projets de recherche stratégiques.
NVIDIA dans une position délicate
L’entreprise, dont les produits sont au cœur de l’explosion de l’IA générative mondiale, se trouve à nouveau au centre d’enjeux géopolitiques. Déjà contrainte par les autorités américaines à limiter les capacités de ses GPU destinés à la Chine, NVIDIA tente depuis plusieurs mois de maintenir sa présence sur ce marché stratégique sans enfreindre les règles d’exportation de Washington ni celles de cybersécurité de Pékin.
Le modèle H20 avait été conçu pour répondre à ces contraintes, tout en conservant des performances acceptables pour les grands modèles d’IA. Les accusations de vulnérabilités ou de « portes dérobées » pourraient compliquer davantage l’équilibre déjà précaire de la société entre régulations opposées.


                        Cet article publirédactionnel est publié dans le cadre d'une collaboration commerciale",,envoyé,"Voici un résumé du texte en 4 phrases :

L'Administration chinoise du cyberespace (CAC) a convoqué NVIDIA pour discuter de vulnérabilités de sécurité dans ses puces H20, destinées au marché chinois. Les puces sont accusées d'intégrer des fonctions de tracking et de remote shutdown, permettant une désactivation unilatérale ou une localisation des appareils. Le CAC a exigé des preuves techniques et documentaires de NVIDIA pour démontrer sa conformité avec la législation chinoise en matière de cybersécurité et de souveraineté numérique. NVIDIA, déjà soumise à des restrictions des autorités américaines, est dans une position délicate en cherchant à maintenir sa présence sur le marché chinois tout en répondant aux exigences de cybersécurité de Pékin."
"Alibaba présente ses cockpits intelligents, lunettes IA et partenariats stratégiques au WAIC 2025",01/08/2025,"À l’occasion de la World Artificial Intelligence Conference (WAIC) 2025, Alibaba Cloud a présenté plusieurs démonstrateurs et partenariats illustrant l’intégration croissante de ses modèles de langage dans des cas d’usage concrets, notamment dans les domaines de la mobilité, des objets connectés et de la gestion urbaine.
Cockpit intelligent : convergence entre IA multimodale et interface homme-machine
Parmi les annonces phares, un nouveau cockpit intelligent développé en partenariat avec Qualcomm et Banma a été dévoilé. Il repose sur une solution multimodale (LMM) propulsée par le modèle Qwen d’Alibaba, intégrée à la dernière plateforme Snapdragon 8397. Le système permettrait des interactions vocales contextuelles dans le véhicule, allant de la recherche d’itinéraire à la gestion des préférences de conduite, avec une approche proactive – un point présenté comme différenciant par Alibaba.
L’assistant embarqué, Yan AI, exploite des capacités combinées de vision, de traitement du langage et de raisonnement pour anticiper certains comportements de l’utilisateur. Ces fonctionnalités s’inscrivent dans une tendance plus large d’“assistants embarqués augmentés”, déjà explorée par d’autres constructeurs et fournisseurs technologiques.
Application à l’échelle urbaine : cas d’usage avec Signify
Alibaba a également mis en avant l’intégration de Qwen dans l’agent GenAI de Signify (anciennement Philips Lighting). Cet agent serait capable d'interagir avec le système d’éclairage urbain Interact City Flex, permettant la création de scénarios d’optimisation énergétique via des instructions en langage naturel.
L’objectif affiché est double : réduction de la consommation énergétique et amélioration de la maintenance via la détection automatique d’anomalies. Si cette démonstration reste encore au stade expérimental dans de nombreuses villes, elle témoigne de la volonté des acteurs industriels d’associer IA générative et infrastructures critiques.
Lunettes connectées : Alibaba entre sur le marché du wearable IA
Autre lancement remarqué : les Quark AI Glasses, lunettes connectées intégrant les modèles Qwen. Présentées comme un assistant personnel à porter au quotidien, elles combinent fonctions de traduction, transcription, navigation, et paiement vocal.
Ce positionnement rappelle celui d’autres initiatives sur le marché du wearable computing, où l’intégration fluide de l’IA reste un défi en matière d’ergonomie, d’autonomie et d’usage réel. Le lancement commercial est prévu d’ici fin 2025 en Chine.
Qwen, un modèle open source à large diffusion
Enfin, Alibaba a rappelé la progression de sa série de modèles Qwen, revendiquant plus de 400 millions de téléchargements et plus de 140 000 modèles dérivés. Ce positionnement open source, déjà adopté par plusieurs géants chinois comme Baidu ou Huawei, contribue à renforcer leur influence dans l’écosystème mondial des LLMs.",,envoyé,"Voici un résumé du texte en 4 phrases :

Alibaba Cloud a présenté lors de la World Artificial Intelligence Conference (WAIC) 2025 des démonstrateurs et partenariats illustrant l'intégration de ses modèles de langage (LLMs) dans des domaines concrets, tels que la mobilité, les objets connectés et la gestion urbaine. Il a dévoilé un nouveau cockpit intelligent qui utilise une solution multimodale (LMM) pour fournir des interactions vocales contextuelles dans les véhicules. Il a également mis en avant l'intégration de Qwen dans un agent urbain pour réduire la consommation énergétique et améliorer la maintenance via des instructions en langage naturel. Enfin, Alibaba a présenté ses lunettes connectées intégrant Qwen, un modèle open source qui a été téléchargé plus de 400 millions de fois et dérivé en plus de 140 000 modèles."
Mission ICHIBAN : la coopération robotique prend son envol à bord de l’ISS,01/08/2025,"L’agence spatiale allemande (DLR) et l'Agence japonaise pour l'exploration aérospatiale (JAXA) annoncent que la mission de coopération internationale ""ICHIBAN"" a été couronnée de succès. Pour la première fois, deux robots d’assistance aux astronautes issus de programmes nationaux distincts ont communiqué et coopéré en orbite à bord de l'ISS.
L'un des objectifs de la mission ICHIBAN (première en japonais,) qui s'est achevée le 29 juillet dernier, était de tester la coordination de plusieurs robots distincts opérant simultanément et en temps réel à bord de l’ISS.
Les deux robots impliqués dans l'expérience sont CIMON, développé par le DLR, Airbus et IBM ainsi qu'Int-Ball2, conçu par la JAXA, installés respectivement dans les modules d'expérimentation européen Columbus et japonais Kibo.
Déployé pour la première fois en 2018, CIMON (Crew Interactive Mobile Companion) est un robot sphérique, de la taille d'un ballon, imprimé en 3D, propulsé par les technologies vocales et cognitives de watsonx, la plateforme IA d’IBM. Durant la mission ICHIBAN, CIMON a été opéré par BIOTESC, le centre suisse de l’ESA spécialisé dans les opérations scientifiques à bord de la station internationale.
De son côté, Int-Ball2 est une évolution du premier drone caméra de la JAXA. Intégré depuis 2023 dans le module japonais, il permet à la cellule de contrôle au sol à Tsukuba (Japon) de filmer à distance les activités des astronautes, optimisant ainsi la documentation scientifique sans mobiliser l’équipage de la station spatiale internationale. Jusqu’ici, aucune capacité d’interaction avec d’autres robots n’avait été envisagée.
La démonstration a été menée par Takuya Onishi, astronaute de la JAXA à bord de l’ISS. Du module Columbus, il a transmis des commandes vocales à CIMON, qui a servi d’interface linguistique intelligente. L’instruction a été traitée par la plateforme watsonx d’IBM, avant d’être traduite en commandes opérationnelles adressées à Int-Ball2.
Ce dernier a alors navigué dans le module Kibo  pour chercher et localiser divers objets cachés : un Rubik’s Cube, un marteau, plusieurs tournevis, et une ancienne version d’Int-Ball mise hors service. Il a ensuite transmis les images en direct à l’écran de CIMON, permettant à Onishi de vérifier visuellement leur position à distance.

Crédit : JAXA/DLR;Illustration Tableau de collaboration de la mission ICHIBAN
L'astronaute donne une instruction vocale à CIMON pour qu'Int-Ball2 effectue une tâche (étape ①). CIMON transmet cette commande vocale à un serveur d’IA situé au sol, qui analyse l’intention de la commande (étapes ② et ③). Retour d’instruction vers l’ISS : une fois traitée, la commande est renvoyée depuis le sol via le LAN de la station (Joint Station LAN/NASA) à CIMON, qui la transmet à Int-Ball2 (étape ④). Celui-ci agit en conséquence dans le module japonais ""Kibo"", effectue sa tâche (par exemple localiser un objet), puis renvoie les images et données de position à CIMON.
L’innovation réside dans le fait que, jusqu’alors, les images capturées par Int-Ball2 ne pouvaient être transmises qu’au centre de contrôle de Tsukuba. La possibilité de les envoyer en temps réel à un autre robot à bord ouvre un nouveau champ pour les interactions robotiques distribuées en environnement orbital.
Une première étape qui prend toute son importance à l'aune des futures missions lunaires et martiennes.",,envoyé,"Voici un résumé des points clés du texte en 4 phrases maximum :

L'agence spatiale allemande (DLR) et l'Agence japonaise pour l'exploration aérospatiale (JAXA) ont réussi la mission ICHIBAN, qui a testé la coordination de deux robots nationaux distincts pour la première fois en orbite à bord de l'ISS. Les deux robots, CIMON (DA) et Int-Ball2 (JAXA), ont communiqué et coopéré pour effectuer des tâches telles que la localisation d'objets. La mission a démontré la possibilité de transmissions en temps réel entre les robots, ouvrant de nouvelles perspectives pour les interactions robotiques distribuées en environnement orbital. Cette expertise est essentielle pour les futures missions lunaires et martiennes."
Orange Business obtient le visa de sécurité SecNumCloud pour son offre Cloud Avenue SecNum,01/08/2025,"Orange Business, la branche B2B de l’opérateur télécom français, a récemment obtenu la qualification SecNumCloud délivrée par l’Agence nationale de la sécurité des systèmes d'information (ANSSI) pour son offre Cloud Avenue SecNum. Cette certification atteste que son infrastructure IaaS (Infrastructure as a Service) répond aux plus hauts standards de sécurité et de conformité en matière de protection des données.
Avec ce visa, Orange Business consolide son positionnement dans l’écosystème du ""cloud de confiance"". Le référentiel SecNumCloud, considéré comme le plus rigoureux en Europe, garantit que les données sont hébergées dans un environnement sécurisé, maîtrisé, et conforme aux exigences françaises et européennes en matière de souveraineté numérique, y compris vis-à-vis des risques juridiques et géopolitiques.
Une réponse ciblée aux secteurs critiques
Déployée dans un data center écoresponsable à Grenoble et opérée par des équipes françaises, la plateforme Cloud Avenue SecNum repose sur une architecture modulaire de type ""as a service"", permettant aux clients de renforcer leur autonomie technologique tout en s’appuyant sur des dispositifs de sécurité avancés : chiffrement, gestion des clés, isolation réseau, contrôle d’accès, protection physique des installations et traçabilité complète des actions.
Cette localisation permet à Orange Business de répondre aux besoins des organisations soumises à des exigences strictes de souveraineté, notamment dans les secteurs de la défense, de la santé, de la finance, de l’industrie ou encore des services publics.
Avec cette qualification, l'opérateur rejoint le cercle restreint d’acteurs déjà certifiés, tels qu’OVHcloud ou 3DS Outscale. Il attend également la qualification SecNumCloud pour son projet Bleu, co-développé avec Capgemini, qui vise à proposer les services de Microsoft dans un environnement souverain, hors du périmètre des lois extraterritoriales américaines. L'homologation est espérée au premier semestre 2026.",,envoyé,"Voici un résumé du texte en 4 phrases maximum, en insistant sur les points clés :

Orange Business, la branche B2B d'Orange, a obtenu la certification SecNumCloud pour son offre Cloud Avenue SecNum, qui répond aux plus hauts standards de sécurité et de conformité pour la protection des données. Cette certification de l'ANSSI garantit que les données sont hébergées dans un environnement sécurisé et conforme aux exigences françaises et européennes en matière de souveraineté numérique. La plateforme Cloud Avenue SecNum est déployée dans un data center écoresponsable à Grenoble et est conçue pour répondre aux besoins des organisations soumises à des exigences strictes de souveraineté, notamment dans les secteurs de la défense, de la santé et de la finance. Cette qualification permet à Orange Business de consolidé son positionnement dans l'écosystème du ""cloud de confiance""."
